{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Essentials: Data Cleaning\n",
    "    Bryant McArthur\n",
    "    Math 403\n",
    "    October 11, 2022\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "The g\\_t\\_results.csv file is a set of parent-reported scores on their child's Gifted and Talented tests. \n",
    "The two tests, OLSAT and NNAT, are used by NYC to determine if children are qualified for gifted programs.\n",
    "The OLSAT Verbal has 16 questions for Kindergardeners and 30 questions for first, second, and third graders.\n",
    "The NNAT has 48 questions. \n",
    "Using this dataset, answer the following questions.\n",
    "\n",
    "\n",
    "1) What column has the highest number of null values and what percent of its values are null? Print the answer as a tuple with (column name, percentage). Make sure the second value is a percent.\n",
    "\n",
    "2) List the columns that should be numeric that aren't. Print the answer as a tuple.\n",
    "\n",
    "3) How many third graders have scores outside the valid range for the OLSAT Verbal Score? Print the answer\n",
    "\n",
    "4) How many data values are missing (NaN)? Print the number.\n",
    "\n",
    "Each part is one point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('School Assigned', 0.7521367521367521)\n",
      "('OLSAT Verbal Score', 'OLSAT Verbal Percentile', 'NNAT Non Verbal Raw Score')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-6e3687cb5439>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  third_grade['OLSAT Verbal Score'] = third_grade['OLSAT Verbal Score'].to_numpy('float64')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\computation\\expressions.py:203: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv\n",
    "df = pd.read_csv('g_t_results.csv')\n",
    "print((df.isna().sum().idxmax(), df.isna().sum().max() / df['School Assigned'].size))\n",
    "\n",
    "# get numeric columns\n",
    "numeric_cols = ('OLSAT Verbal Score',\n",
    "                 'OLSAT Verbal Percentile',\n",
    "                 'NNAT Non Verbal Raw Score',\n",
    "                )\n",
    "print(numeric_cols)\n",
    "\n",
    "# Rename\n",
    "df = df.rename({'Entering Grade Level': 'Grade'}, axis=1)\n",
    "\n",
    "# Third grade df\n",
    "third_grade = df.query(\"Grade == '3'\")\n",
    "third_grade['OLSAT Verbal Score'] = third_grade['OLSAT Verbal Score'].to_numpy('float64')\n",
    "\n",
    "# Filter\n",
    "missing = (third_grade['OLSAT Verbal Score'] > 30) + (third_grade['OLSAT Verbal Score'] < 0)\n",
    "print(missing.sum())\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "imdb.csv contains a small set of information about 99 movies. Clean the data set by doing the following in order: \n",
    "\n",
    "1) Remove duplicate rows by dropping the first **or** last. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "2) Drop all rows that contain missing data. Print the shape of the dataframe after removing the rows.\n",
    "\n",
    "3) Remove rows that have data outside valid data ranges and explain briefly how you determined your ranges for each column.\n",
    "\n",
    "4) Identify and drop columns with three or fewer different values. Print a tuple with the names of the columns dropped.\n",
    "\n",
    "5) Convert the titles to all lower case.\n",
    "\n",
    "Print the first five rows of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 13)\n",
      "(64, 13)\n",
      "('color', 'language')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>title_year</th>\n",
       "      <th>country</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>actors</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shane Black</td>\n",
       "      <td>195</td>\n",
       "      <td>408992272.0</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>iron man 3</td>\n",
       "      <td>2013</td>\n",
       "      <td>USA</td>\n",
       "      <td>200000000.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Robert Downey Jr.,Jon Favreau,Don Cheadle</td>\n",
       "      <td>95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quentin Tarantino</td>\n",
       "      <td>187</td>\n",
       "      <td>54116191.0</td>\n",
       "      <td>Crime|Drama|Mystery|Thriller|Western</td>\n",
       "      <td>the hateful eight</td>\n",
       "      <td>2015</td>\n",
       "      <td>USA</td>\n",
       "      <td>44000000.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Craig Stark,Jennifer Jason Leigh,ZoÃ« Bell</td>\n",
       "      <td>114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenneth Lonergan</td>\n",
       "      <td>186</td>\n",
       "      <td>46495.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>margaret</td>\n",
       "      <td>2011</td>\n",
       "      <td>usa</td>\n",
       "      <td>14000000.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Matt Damon,Kieran Culkin,John Gallagher Jr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>186</td>\n",
       "      <td>258355354.0</td>\n",
       "      <td>Adventure|Fantasy</td>\n",
       "      <td>the hobbit: the desolation of smaug</td>\n",
       "      <td>2013</td>\n",
       "      <td>USA</td>\n",
       "      <td>225000000.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Aidan Turner,Adam Brown,James Nesbitt</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>173</td>\n",
       "      <td>623279547.0</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>the avengers</td>\n",
       "      <td>2012</td>\n",
       "      <td>USA</td>\n",
       "      <td>220000000.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Chris Hemsworth,Robert Downey Jr.,Scarlett Joh...</td>\n",
       "      <td>123000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       director_name  duration        gross  \\\n",
       "1        Shane Black       195  408992272.0   \n",
       "2  Quentin Tarantino       187   54116191.0   \n",
       "3   Kenneth Lonergan       186      46495.0   \n",
       "4      Peter Jackson       186  258355354.0   \n",
       "8        Joss Whedon       173  623279547.0   \n",
       "\n",
       "                                 genres                          movie_title  \\\n",
       "1               Action|Adventure|Sci-Fi                           iron man 3   \n",
       "2  Crime|Drama|Mystery|Thriller|Western                    the hateful eight   \n",
       "3                                 Drama                             margaret   \n",
       "4                     Adventure|Fantasy  the hobbit: the desolation of smaug   \n",
       "8               Action|Adventure|Sci-Fi                         the avengers   \n",
       "\n",
       "   title_year country       budget  imdb_score  \\\n",
       "1        2013     USA  200000000.0         7.2   \n",
       "2        2015     USA   44000000.0         7.9   \n",
       "3        2011     usa   14000000.0         6.5   \n",
       "4        2013     USA  225000000.0         7.9   \n",
       "8        2012     USA  220000000.0         8.1   \n",
       "\n",
       "                                              actors  movie_facebook_likes  \n",
       "1          Robert Downey Jr.,Jon Favreau,Don Cheadle                 95000  \n",
       "2          Craig Stark,Jennifer Jason Leigh,ZoÃ« Bell                114000  \n",
       "3        Matt Damon,Kieran Culkin,John Gallagher Jr.                     0  \n",
       "4              Aidan Turner,Adam Brown,James Nesbitt                 83000  \n",
       "8  Chris Hemsworth,Robert Downey Jr.,Scarlett Joh...                123000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv\n",
    "imdb = pd.read_csv('imdb.csv')\n",
    "\n",
    "# Filter duplicates and NaNs\n",
    "imdb.drop_duplicates(keep='first', inplace=True)\n",
    "print(imdb.shape)\n",
    "imdb.dropna(inplace=True)\n",
    "print(imdb.shape)\n",
    "\n",
    "# Make Numpy\n",
    "imdb = imdb.replace(('Nan', 'Null'), np.nan)\n",
    "imdb = imdb[(imdb.imdb_score > 0)]\n",
    "imdb = imdb[(imdb.duration < 200)]\n",
    "imdb = imdb[(imdb.duration > 0)]\n",
    "imdb.dropna(inplace=True)\n",
    "\n",
    "# Drop cols\n",
    "drop_cols = list()\n",
    "for column in imdb.columns:\n",
    "    if len(imdb[column].unique()) <= 3:\n",
    "        drop_cols.append(column)\n",
    "\n",
    "print(tuple(drop_cols))\n",
    "imdb.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "# Lowercase titles\n",
    "imdb['movie_title'] = imdb['movie_title'].str.lower()\n",
    "imdb.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "basketball.csv contains data for all NBA players between 2001 and 2018.\n",
    "Each row represents a player's stats for a year.\n",
    "\n",
    "Create two new features:\n",
    "\n",
    "    career_length (int): number of years player has been playing (start at 0).\n",
    "    \n",
    "    target (str): The target team if the player is leaving. If the player is retiring, the target should be 'retires'.\n",
    "                  A player is retiring if their name doesn't exist the next year.\n",
    "                  (Set the players in 2019 to NaN).\n",
    "\n",
    "Remove all duplicate players in each year.\n",
    "Remove all rows except those where a player changes team, that is, target is not null nor 'retires'.\n",
    "\n",
    "Drop the player, year, and team_id columns.\n",
    "\n",
    "Return the first 10 lines of your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>per</th>\n",
       "      <th>ws</th>\n",
       "      <th>bpm</th>\n",
       "      <th>career length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>27</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>PHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>24</td>\n",
       "      <td>15.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3</td>\n",
       "      <td>MEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>33</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>14</td>\n",
       "      <td>HOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>13</td>\n",
       "      <td>PHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>29</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>9</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>31</td>\n",
       "      <td>14.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>SAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>25</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>6</td>\n",
       "      <td>CHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>29</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>SAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>28</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>7</td>\n",
       "      <td>MIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age   per   ws  bpm  career length target\n",
       "453   27   8.2  1.0 -2.5              5    PHO\n",
       "461   24  13.0  1.2 -0.9              2    ATL\n",
       "462   24  15.9  6.2  2.9              3    MEM\n",
       "464   33  12.7  3.7 -1.9             14    HOU\n",
       "467   32  11.8  5.3  0.7             13    PHO\n",
       "477   29   7.5  1.1 -2.8              9    MIN\n",
       "482   31  14.1  1.9 -0.2             10    SAS\n",
       "489   25  14.1  2.9 -2.4              6    CHO\n",
       "490   29  12.6  2.8  0.1              2    SAC\n",
       "493   28  13.0  0.0 -3.2              7    MIL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv make career length\n",
    "df = pd.read_csv('basketball.csv')\n",
    "df['career length'] = df.apply(lambda x: x['year'] - df.loc[bb['player'] == x['player'],['year']].min(), axis=1)\n",
    "\n",
    "# Drop duplicates and make target col\n",
    "df.drop_duplicates(subset=['player','year'], inplace=True)\n",
    "df['target'] = df.groupby(['player'])['team_id'].shift(1)\n",
    "\n",
    "# Account for retiring players\n",
    "for row in df[df['target'].isna()].index:\n",
    "    if df.loc[row,'year'] != 2019:\n",
    "        df.loc[row, 'target'] == 'retires'\n",
    "        \n",
    "# Iterate through rows in bb index\n",
    "for row in bb.index:\n",
    "    if df.loc[row, 'team_id'] == df.loc[row, 'target']:\n",
    "        df.drop(row, inplace=True)\n",
    "        \n",
    "# Clean Nans\n",
    "df.dropna(inplace=True)\n",
    "df.drop(['player','year','team_id'], axis=1, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Load housing.csv into a dataframe with index=0. Descriptions of the features are in housing_data_description.txt.  \n",
    "The goal is to construct a regression model that predicts SalePrice using the other features of the dataset.  Do this as follows:\n",
    "\n",
    "\t1) Identify and handle the missing data.  Hint: Dropping every row with some missing data is not a good choice because it gives you an empty dataframe.  What can you do instead?\n",
    "    FIXME\n",
    "\t2) Identify the variable with nonnumeric values that are misencoded as numbers.  One-hot encode it. Hint: don't forget to remove one of the encoded columns to prevent collinearity with the constant column (which you will add later).\n",
    "    \n",
    "    3) Add a constant column to the dataframe.\n",
    "\n",
    "    4) Save a copy of the dataframe.\n",
    "\n",
    "\t5) Choose four categorical featrues that seem very important in predicting SalePrice. One-hot encode these features and remove all other categorical features.\n",
    "\t\t\n",
    "\t6) Run an OLS using all numerical data regression on your model.  \n",
    "\n",
    "\t\n",
    "Print the ten features that have the highest coef in your model and the summary. Don't print the OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing.csv', index_col=0)\n",
    "\n",
    "# find nan columns and drop\n",
    "nan_cols = list()\n",
    "for col in df.columns:\n",
    "    if pd.isna(df[col].value_counts(dropna=False).idxmax()):\n",
    "        nan_cols.append(col)\n",
    "    \n",
    "    else:\n",
    "        # Fill Nan with mode\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        \n",
    "df = df.drop(columns=nan_cols)\n",
    "\n",
    "# One-hot categorize\n",
    "df = pd.get_dummies(df, columns=['MSSubClass'], drop_first=True)\n",
    "\n",
    "# Add constant column\n",
    "df['const'] = np.ones(df.shape[0])\n",
    "\n",
    "# make a copy\n",
    "new_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       OverallQual_10\n",
      "1        OverallQual_9\n",
      "2        OverallQual_8\n",
      "3                const\n",
      "4        OverallQual_7\n",
      "5        OverallQual_6\n",
      "6        OverallQual_5\n",
      "7        OverallQual_4\n",
      "8    HouseStyle_2.5Fin\n",
      "9        OverallQual_3\n",
      "Name: index, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# keep the important cols and price\n",
    "important_cols = ['SalePrice','HouseStyle','KitchenQual','OverallCond','OverallQual']\n",
    "new_df = new_df.loc[:, important_cols]\n",
    "new_df = pd.get_dummies(new_df, columns=important_cols[1:], drop_first=True)\n",
    "new_df['const'] = np.ones(new_df.shape[0])\n",
    "\n",
    "# run regression\n",
    "y = new_df['SalePrice']\n",
    "X = new_df.iloc[:,1:]\n",
    "reg = sm.OLS(y, X).fit()\n",
    "\n",
    "# save as html then as pd.DataFrame\n",
    "a = reg.summary()\n",
    "reg_as_html = a.tables[1].as_html()\n",
    "reg_df = pd.read_html(reg_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "# sorts and prints top 10 highest features\n",
    "reg_df = reg_df.sort_values(by='coef', ascending=False).reset_index()\n",
    "print(reg_df['index'].iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              SalePrice   R-squared:                       0.711\n",
      "Model:                            OLS   Adj. R-squared:                  0.706\n",
      "Method:                 Least Squares   F-statistic:                     130.5\n",
      "Date:                Tue, 11 Oct 2022   Prob (F-statistic):               0.00\n",
      "Time:                        15:23:13   Log-Likelihood:                -17638.\n",
      "No. Observations:                1460   AIC:                         3.533e+04\n",
      "Df Residuals:                    1432   BIC:                         3.548e+04\n",
      "Df Model:                          27                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "HouseStyle_1.5Unf -3.564e+04   1.21e+04     -2.944      0.003   -5.94e+04   -1.19e+04\n",
      "HouseStyle_1Story  3224.3551   3972.786      0.812      0.417   -4568.750     1.1e+04\n",
      "HouseStyle_2.5Fin  3.341e+04   1.59e+04      2.100      0.036    2204.223    6.46e+04\n",
      "HouseStyle_2.5Unf -2.557e+04   1.36e+04     -1.880      0.060   -5.23e+04    1116.326\n",
      "HouseStyle_2Story  1.224e+04   4299.926      2.846      0.004    3800.718    2.07e+04\n",
      "HouseStyle_SFoyer -8225.0495   7953.767     -1.034      0.301   -2.38e+04    7377.234\n",
      "HouseStyle_SLvl    7200.4778   6464.141      1.114      0.266   -5479.724    1.99e+04\n",
      "KitchenQual_Fa    -6.241e+04   9789.161     -6.376      0.000   -8.16e+04   -4.32e+04\n",
      "KitchenQual_Gd    -2.694e+04   5964.608     -4.517      0.000   -3.86e+04   -1.52e+04\n",
      "KitchenQual_TA    -4.729e+04   6443.461     -7.340      0.000   -5.99e+04   -3.47e+04\n",
      "OverallCond_2     -1.486e+04   6.47e+04     -0.230      0.818   -1.42e+05    1.12e+05\n",
      "OverallCond_3      -2.17e+04    6.1e+04     -0.356      0.722   -1.41e+05    9.79e+04\n",
      "OverallCond_4     -7295.0907   6.19e+04     -0.118      0.906   -1.29e+05    1.14e+05\n",
      "OverallCond_5     -3575.6363   6.17e+04     -0.058      0.954   -1.25e+05    1.17e+05\n",
      "OverallCond_6       985.8301   6.17e+04      0.016      0.987    -1.2e+05    1.22e+05\n",
      "OverallCond_7      2400.9697   6.17e+04      0.039      0.969   -1.19e+05    1.23e+05\n",
      "OverallCond_8     -6339.6060   6.19e+04     -0.102      0.918   -1.28e+05    1.15e+05\n",
      "OverallCond_9     -5173.8947   6.24e+04     -0.083      0.934   -1.28e+05    1.17e+05\n",
      "OverallQual_2      1388.4728   4.99e+04      0.028      0.978   -9.66e+04    9.94e+04\n",
      "OverallQual_3      1.958e+04   4.55e+04      0.431      0.667   -6.96e+04    1.09e+05\n",
      "OverallQual_4      3.551e+04   4.48e+04      0.793      0.428   -5.23e+04    1.23e+05\n",
      "OverallQual_5       5.61e+04   4.48e+04      1.253      0.211   -3.17e+04    1.44e+05\n",
      "OverallQual_6      7.848e+04   4.48e+04      1.752      0.080   -9382.300    1.66e+05\n",
      "OverallQual_7      1.136e+05   4.49e+04      2.532      0.011    2.56e+04    2.02e+05\n",
      "OverallQual_8      1.735e+05    4.5e+04      3.857      0.000    8.52e+04    2.62e+05\n",
      "OverallQual_9        2.5e+05   4.56e+04      5.486      0.000    1.61e+05    3.39e+05\n",
      "OverallQual_10     3.186e+05   4.63e+04      6.884      0.000    2.28e+05    4.09e+05\n",
      "const              1.202e+05   4.44e+04      2.706      0.007    3.31e+04    2.07e+05\n",
      "==============================================================================\n",
      "Omnibus:                      385.034   Durbin-Watson:                   1.976\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4357.066\n",
      "Skew:                           0.893   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.272   Cond. No.                         281.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "Using the copy of the dataframe you created in Problem 4, one-hot encode all the categorical variables.\n",
    "Print the shape of the dataframe and run OLS.\n",
    "\n",
    "Print the ten features that have the highest coef in your model and the summary.\n",
    "Write a couple of sentences discussing which model is better and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 245)\n",
      "0    RoofMatl_Membran\n",
      "1      RoofMatl_Metal\n",
      "2    RoofMatl_WdShngl\n",
      "3    RoofMatl_Tar&Grv\n",
      "4    RoofMatl_CompShg\n",
      "5       RoofMatl_Roll\n",
      "6    RoofMatl_WdShake\n",
      "7       GarageCond_TA\n",
      "8       GarageCond_Gd\n",
      "9       GarageCond_Po\n",
      "Name: index, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print(df.shape)\n",
    "\n",
    "# Get list of columns we want\n",
    "cols = list(df.columns)\n",
    "cols.remove('SalePrice')\n",
    "y = df['SalePrice']\n",
    "X = df.loc[:, cols]\n",
    "\n",
    "# Run regression\n",
    "results = sm.OLS(y, X).fit()\n",
    "\n",
    "# Make html and df\n",
    "summary_results = results.summary()\n",
    "results_as_html = summary_results.tables[1].as_html()\n",
    "results_df = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "\n",
    "# sorts and prints\n",
    "results_df = results_df.sort_values(by='coef', ascending=False).reset_index()\n",
    "print(results_df['index'].iloc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obviously way more helpful to clean the data before using it and running a regression. Filtering for variables that matter to what you want make way more sense than running it with everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
